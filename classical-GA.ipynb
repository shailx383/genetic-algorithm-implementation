{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from generation import Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_SPACE = {\n",
    "    'k_size_a': [1, 3, 5],\n",
    "    'k_size_b': [1, 3, 5],\n",
    "    'k_size_c': [1, 3, 5],\n",
    "    'k_size_d': [1, 3, 5],\n",
    "    'out_channels_a': [8, 16, 32, 64],\n",
    "    'out_channels_b': [8, 16, 32, 64],\n",
    "    'out_channels_c': [8, 16, 32, 64],\n",
    "    'out_channels_d': [8, 16, 32, 64],\n",
    "    'include_pool_a': [True, False],\n",
    "    'include_pool_b': [True, False],\n",
    "    'include_pool_c': [True, False],\n",
    "    'include_pool_d': [True, False],\n",
    "    'pool_type_a': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_b': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_c': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_d': ['max_pooling','avg_pooling'],\n",
    "    'activation_type_a': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_b': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_c': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_d': ['relu', 'tanh', 'elu', 'selu'], \n",
    "    'include_b': [True],\n",
    "    'include_c': [True],\n",
    "    'include_d': [True],\n",
    "    'include_BN_a': [True, False],\n",
    "    'include_BN_b': [True, False],\n",
    "    'include_BN_c': [True, False],\n",
    "    'include_BN_d': [True, False],\n",
    "    'skip_connection': [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "FIT_SURVIVAL_RATE = 0.5\n",
    "UNFIT_SURVIVAL_RATE = 0.2\n",
    "MUTATION_RATE = 0.1\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "kwargs = {'batch_size': 64, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(trainset, **kwargs)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(testset, **kwargs)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, chromosome):\n",
    "        super().__init__()\n",
    "        self.block = chromosome.model\n",
    "        if chromosome.phase == 0:\n",
    "            in_channels = 3\n",
    "            if(chromosome.genes['include_d']):\n",
    "                out_channels = chromosome.genes['out_channels_d']\n",
    "            elif(chromosome.genes['include_c']):\n",
    "                out_channels = chromosome.genes['out_channels_c']\n",
    "            elif(chromosome.genes['include_b']):\n",
    "                out_channels = chromosome.genes['out_channels_b']\n",
    "            else:\n",
    "                out_channels = chromosome.genes['out_channels_a']\n",
    "        else:\n",
    "            if(chromosome.prev_best.genes['include_b']):\n",
    "                in_channels = chromosome.prev_best.genes['out_channels_b']\n",
    "            else:\n",
    "                in_channels = chromosome.prev_best.genes['out_channels_a']\n",
    "            if(chromosome.genes['include_b']):\n",
    "                out_channels = chromosome.genes['out_channels_b']\n",
    "            else:\n",
    "                out_channels = chromosome.genes['out_channels_a']\n",
    "        # self.skip = nn.Conv2d(in_channels, out_channels, 1)\n",
    " \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(out_channels*chromosome.out_dimensions**2,10)\n",
    " \n",
    "    def forward(self, x, chromosome):\n",
    "        # if chromosome.genes['skip_connection']:\n",
    "        #     y = x\n",
    "        #     if chromosome.phase != 0:\n",
    "        #         y = chromosome.prev_best.model(x)\n",
    "        #     y = self.skip(y)\n",
    "        x=self.block(x)\n",
    "        # if chromosome.genes['skip_connection']:\n",
    "        #     x = x + y\n",
    "        x = self.fc(self.flatten(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    def __init__(self,phase:int,prev_best,genes:dict,train_loader,test_loader):\n",
    "        self.phase = phase\n",
    "        self.prev_best = prev_best\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.genes = genes\n",
    "        self.out_dimensions = prev_best.out_dimensions if phase!=0 else 32\n",
    "        self.fitness = -1 \n",
    "        self.model:nn.Module = self.build_model()\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        if self.fitness==-1:\n",
    "            self.fitness = self.fitness_function(train_loader,test_loader)\n",
    " \n",
    "    def build_model(self)->nn.Module:\n",
    "        if(self.prev_best!=None):\n",
    "            prev_best_model:nn.Module = self.prev_best.model\n",
    "        new_model_modules = []\n",
    "        padding_size = 0\n",
    "        if(self.genes['skip_connection']):\n",
    "            padding_size = 16 if self.phase==0 else self.prev_best.out_dimensions//2\n",
    "        if(self.out_dimensions<self.genes['k_size_a']):\n",
    "            self.fitness = 0\n",
    "            return nn.Sequential()\n",
    "        \n",
    "        if(self.phase!=0):\n",
    "            # layer_a = nn.Conv2d(self.prev_best.genes['out_channels_b'] if self.prev_best.genes['include_b'] else self.prev_best.genes['out_channels_a'],self.genes['out_channels_a'],self.genes['k_size_a'],padding = self.genes['k_size_a']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_a = nn.Conv2d(self.prev_best.genes['out_channels_b'] if self.prev_best.genes['include_b'] else self.prev_best.genes['out_channels_a'],self.genes['out_channels_a'],self.genes['k_size_a'],padding = 'same')\n",
    "        else:\n",
    "            # layer_a = nn.Conv2d(3,self.genes['out_channels_a'],self.genes['k_size_a'],padding = self.genes['k_size_a']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_a = nn.Conv2d(3,self.genes['out_channels_a'],self.genes['k_size_a'],padding = 'same')\n",
    "        # self.out_dimensions = (self.out_dimensions-self.genes['k_size_a']+1)\n",
    "        new_model_modules.append(layer_a)\n",
    "        if(self.genes['activation_type_a']=='relu'):\n",
    "            new_model_modules.append(nn.ReLU())\n",
    "        elif(self.genes['activation_type_a']=='elu'):\n",
    "            new_model_modules.append(nn.ELU())\n",
    "        elif(self.genes['activation_type_a']=='selu'):\n",
    "            new_model_modules.append(nn.SELU())\n",
    "        else:\n",
    "            new_model_modules.append(nn.Tanh())\n",
    "        if(self.genes['include_pool_a'] and not self.genes['skip_connection']):\n",
    "            if(self.out_dimensions<2):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            if(self.genes['pool_type_a']=='max_pooling'):\n",
    "                new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                self.out_dimensions = self.out_dimensions//2\n",
    "            elif(self.genes['pool_type_a']=='avg_pooling'):\n",
    "                new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                self.out_dimensions = self.out_dimensions//2\n",
    "            else:\n",
    "                raise Exception('Invalid pool type (a layer)')\n",
    "        \n",
    "        if(self.genes['include_BN_a']):\n",
    "            new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_a']))\n",
    "        \n",
    "        if(self.genes['include_b']):\n",
    "            if(self.out_dimensions<self.genes['k_size_b']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_b)\n",
    "            if(self.genes['activation_type_b']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_b']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_b']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_b'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_b']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_b']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (b layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_b']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_b']))\n",
    "                \n",
    "        if(self.genes['include_c']):\n",
    "            if(self.out_dimensions<self.genes['k_size_c']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_c = nn.Conv2d(self.genes['out_channels_b'],self.genes['out_channels_c'],self.genes['k_size_c'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_c)\n",
    "            if(self.genes['activation_type_c']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_c']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_c']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_c'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_c']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_c']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (c layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_c']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_c']))\n",
    "        \n",
    "        if(self.genes['include_d']):\n",
    "            if(self.out_dimensions<self.genes['k_size_d']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_d = nn.Conv2d(self.genes['out_channels_c'],self.genes['out_channels_d'],self.genes['k_size_d'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_d)\n",
    "            if(self.genes['activation_type_d']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_d']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_d']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_d'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_d']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_d']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (d layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_d']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_d']))\n",
    "        if(self.phase!=0):\n",
    "            new_model = nn.Sequential(prev_best_model,*new_model_modules)\n",
    "        else:\n",
    "            new_model = nn.Sequential(*new_model_modules)\n",
    "        if(self.genes['skip_connection']):\n",
    "            self.out_dimensions = 32 if self.phase==0 else self.prev_best.out_dimensions\n",
    "        # print(new_model)\n",
    "        return new_model            \n",
    " \n",
    "    def fitness_function(self,train_loader,test_loader)->float:\n",
    "        \n",
    "        new_model = FinalModel(self)\n",
    "        #Training loop\n",
    "        optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n",
    "        criterion = F.nll_loss\n",
    "        new_model.to(self.device)\n",
    "        num_epochs = 1\n",
    "        for epoch in range(num_epochs):\n",
    "            pbar = tqdm(train_loader)\n",
    "            new_model.train()\n",
    "            for batch_idx, (data, target) in enumerate(pbar):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = new_model(x = data, chromosome = self)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_description(desc= f'epoch {epoch} loss={loss.item()} batch_id={batch_idx}')\n",
    "            # Training accuracy\n",
    "            '''\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            new_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in train_loader:\n",
    "                    images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = new_model(images,self)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\"Training accuracy: {}\".format(100 * correct / total))\n",
    "            '''\n",
    "            #Testing loop\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            new_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in test_loader:\n",
    "                    images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = new_model(images,self)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\"Validation accuracy: {}\".format(100 * correct / total))\n",
    "        print(f\"Fitness calculated: {100 * correct / total}\")\n",
    "        return 100 * correct / total\n",
    " \n",
    "    def crossover(self, chromosome):\n",
    "        genes1 = self.genes\n",
    "        genes2 = chromosome.genes\n",
    "        keys = genes1.keys()\n",
    "        new_genes = {}\n",
    "        for key in keys:\n",
    "            new_genes[key] = random.choice([genes1[key], genes2[key]])\n",
    "        new_chromosome = Chromosome(self.phase, self.prev_best, new_genes, self.train_loader, self.test_loader)\n",
    "        return new_chromosome \n",
    "    \n",
    "    def mutation(self):\n",
    "        mutated_gene = random.choice(list(self.genes.keys()))\n",
    "        possible_values = [value for value in SEARCH_SPACE[mutated_gene]]\n",
    "        possible_values.remove(self.genes[mutated_gene])\n",
    "        new_gene_value = random.choice(possible_values)\n",
    "        new_genes = self.genes.copy()\n",
    "        new_genes[mutated_gene] = new_gene_value\n",
    "        new_chromosome = Chromosome(self.phase, self.prev_best, new_genes, self.train_loader, self.test_loader)\n",
    "        return new_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generation():\n",
    "    def __init__(self,\n",
    "                 fit_survival_rate: float,\n",
    "                 unfit_survival_rate: float,\n",
    "                 mutation_rate: float,\n",
    "                 pop_size: int,\n",
    "                 phase: int,\n",
    "                 search_space: dict,\n",
    "                 prev_best: Chromosome,\n",
    "                 train_loader,\n",
    "                 test_loader):\n",
    "        self.fit_survival_rate = fit_survival_rate\n",
    "        self.unfit_survival_rate = unfit_survival_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.pop_size = pop_size\n",
    "        self.phase = phase\n",
    "        self.pop = []\n",
    " \n",
    "        for i in range(pop_size):\n",
    "            self.pop.append(Chromosome(phase=phase,\n",
    "                                       prev_best=prev_best,\n",
    "                                       genes=self.make_gene(search_space),\n",
    "                                       train_loader = train_loader,\n",
    "                                       test_loader = test_loader))\n",
    " \n",
    "    def make_gene(self, search_space: dict):\n",
    "        gene = {}\n",
    "        keys = search_space.keys()\n",
    "        for key in keys:\n",
    "            gene[key] = random.choice(search_space[key])\n",
    "        num_layers = 4\n",
    "        if num_layers == 4:\n",
    "            gene['include_a'] = True\n",
    "            gene['include_b'] = True\n",
    "            gene['include_c'] = True\n",
    "            gene['include_d'] = True\n",
    "        # elif num_layers == 3:\n",
    "        #     gene['include_a'] = True\n",
    "        #     gene['include_b'] = True\n",
    "        #     gene['include_c'] = True\n",
    "        #     gene['include_d'] = False\n",
    "        # elif num_layers == 2:\n",
    "        #     gene['include_a'] = True\n",
    "        #     gene['include_b'] = True\n",
    "        #     gene['include_c'] = False\n",
    "        #     gene['include_d'] = False\n",
    "        # else:\n",
    "        #     gene['include_a'] = True\n",
    "        #     gene['include_b'] = False\n",
    "        #     gene['include_c'] = False\n",
    "        #     gene['include_d'] = False\n",
    "        return gene\n",
    " \n",
    "    def sort_pop(self):\n",
    "        sorted_pop = sorted(self.pop,\n",
    "                            key=lambda x: x.fitness,\n",
    "                            reverse=True)\n",
    "        self.pop = sorted_pop\n",
    " \n",
    "    def generate(self):\n",
    "        # print(\"start gen\")\n",
    "        self.sort_pop()\n",
    "        # print(f\"{[i.fitness for i in self.pop]}\")\n",
    "        num_fit_selected = int(self.fit_survival_rate * self.pop_size)\n",
    "        num_unfit_selected = int(self.unfit_survival_rate * self.pop_size)\n",
    "        num_mutate = int(self.mutation_rate * self.pop_size)\n",
    " \n",
    "        new_pop = []\n",
    " \n",
    "        for i in range(num_fit_selected):\n",
    "            if(self.pop[i].fitness!=0):\n",
    "                new_pop.append(self.pop[i])\n",
    " \n",
    "        # print('ok')\n",
    " \n",
    " \n",
    "        for i in range(num_unfit_selected):\n",
    "            # print(i)\n",
    "            if(self.pop[self.pop_size-i-1].fitness!=0):\n",
    "                new_pop.append(self.pop[self.pop_size - i - 1])\n",
    " \n",
    "        if (num_mutate > len(new_pop)):\n",
    "            indices_to_mutate = random.sample(\n",
    "                range(0, len(new_pop)), len(new_pop))\n",
    "        else:\n",
    "            indices_to_mutate = random.sample(\n",
    "                range(0, len(new_pop)), num_mutate)\n",
    "        print(indices_to_mutate, len(new_pop))\n",
    "        for i in indices_to_mutate:\n",
    "            if(new_pop[i].fitness!=0):\n",
    "                new_pop[i] = new_pop[i].mutation()\n",
    " \n",
    "        # print(\"Mutuation done.\", [i.fitness for i in new_pop])\n",
    " \n",
    "        parents_list = []\n",
    "        for i in range(self.pop_size - len(new_pop)):\n",
    "            parents = random.sample(range(0, len(new_pop)), 2)\n",
    "            parents_list.append(tuple(parents))\n",
    " \n",
    "        for p1, p2 in parents_list:\n",
    "            if(new_pop[p1].fitness!=0 and new_pop[p2].fitness!=0):\n",
    "                new_pop.append(new_pop[p1].crossover(new_pop[p2]))\n",
    " \n",
    "        self.pop = new_pop\n",
    "        self.pop_size = len(new_pop)\n",
    "        self.sort_pop()\n",
    "        # print(self.pop_size)\n",
    "        print(\"\\n\\n\")\n",
    "        # print(f\"{[i.fitness for i in self.pop]}\")\n",
    " \n",
    "    def find_fittest(self):\n",
    "        self.sort_pop()\n",
    "        return self.pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.531390905380249 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 186.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 28.61\n",
      "Fitness calculated: 28.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.9219110012054443 batch_id=781: 100%|██████████| 782/782 [00:03<00:00, 235.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.74\n",
      "Fitness calculated: 62.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.9354506731033325 batch_id=781: 100%|██████████| 782/782 [00:02<00:00, 280.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 57.97\n",
      "Fitness calculated: 57.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.393139123916626 batch_id=781: 100%|██████████| 782/782 [00:03<00:00, 221.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 59.85\n",
      "Fitness calculated: 59.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=2.185039520263672 batch_id=781: 100%|██████████| 782/782 [00:07<00:00, 104.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 11.87\n",
      "Fitness calculated: 11.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.49217021465301514 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 185.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 56.08\n",
      "Fitness calculated: 56.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.0322316884994507 batch_id=781: 100%|██████████| 782/782 [00:06<00:00, 126.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 54.7\n",
      "Fitness calculated: 54.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=2.960751533508301 batch_id=781: 100%|██████████| 782/782 [00:09<00:00, 84.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.94\n",
      "Fitness calculated: 49.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2977651357650757 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 148.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 56.88\n",
      "Fitness calculated: 56.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2119650840759277 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 139.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 53.71\n",
      "Fitness calculated: 53.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.488158941268921 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 151.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 55.84\n",
      "Fitness calculated: 55.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.95145583152771 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 133.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 52.04\n",
      "Fitness calculated: 52.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.8079703450202942 batch_id=781: 100%|██████████| 782/782 [00:03<00:00, 244.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 61.21\n",
      "Fitness calculated: 61.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.0160565376281738 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 144.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 61.48\n",
      "Fitness calculated: 61.48\n"
     ]
    }
   ],
   "source": [
    "num_individuals = 15\n",
    "generation = Generation(fit_survival_rate = FIT_SURVIVAL_RATE,\n",
    "                        unfit_survival_rate = UNFIT_SURVIVAL_RATE,\n",
    "                        mutation_rate = MUTATION_RATE,\n",
    "                        pop_size = num_individuals,\n",
    "                        phase = 0,\n",
    "                        search_space = SEARCH_SPACE,\n",
    "                        prev_best = None,\n",
    "                        train_loader = train_loader,\n",
    "                        test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.7687779068946838 batch_id=781: 100%|██████████| 782/782 [00:02<00:00, 289.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 53.41\n",
      "Fitness calculated: 53.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.3457305431365967 batch_id=781: 100%|██████████| 782/782 [00:03<00:00, 198.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 60.86\n",
      "Fitness calculated: 60.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2058898210525513 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 146.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 61.15\n",
      "Fitness calculated: 61.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2792150974273682 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 179.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.66\n",
      "Fitness calculated: 49.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.5856595039367676 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 131.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 56.08\n",
      "Fitness calculated: 56.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.0770578384399414 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 170.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 59.86\n",
      "Fitness calculated: 59.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.5280793905258179 batch_id=781: 100%|██████████| 782/782 [00:06<00:00, 124.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 52.4\n",
      "Fitness calculated: 52.4\n",
      "\n",
      "\n",
      "\n",
      "Fittest in generation 0: 62.74\n",
      "\n",
      "\n",
      "[7] 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.7571377754211426 batch_id=781: 100%|██████████| 782/782 [00:07<00:00, 101.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.98\n",
      "Fitness calculated: 48.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2175872325897217 batch_id=781: 100%|██████████| 782/782 [00:06<00:00, 128.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 58.45\n",
      "Fitness calculated: 58.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2521365880966187 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 168.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.36\n",
      "Fitness calculated: 51.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.177846074104309 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 172.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 61.47\n",
      "Fitness calculated: 61.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.0599979162216187 batch_id=781: 100%|██████████| 782/782 [00:06<00:00, 128.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 55.91\n",
      "Fitness calculated: 55.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.0207905769348145 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 177.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 67.54\n",
      "Fitness calculated: 67.54\n",
      "\n",
      "\n",
      "\n",
      "Fittest in generation 1: 67.54\n",
      "\n",
      "\n",
      "[2] 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.2514493465423584 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 146.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 56.9\n",
      "Fitness calculated: 56.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.6485246419906616 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 137.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.89\n",
      "Fitness calculated: 62.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.7733169794082642 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 140.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 55.47\n",
      "Fitness calculated: 55.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.6091169714927673 batch_id=781: 100%|██████████| 782/782 [00:03<00:00, 198.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 57.31\n",
      "Fitness calculated: 57.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.3043899536132812 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 179.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 59.18\n",
      "Fitness calculated: 59.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.6597741842269897 batch_id=781: 100%|██████████| 782/782 [00:05<00:00, 138.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 54.9\n",
      "Fitness calculated: 54.9\n",
      "\n",
      "\n",
      "\n",
      "Fittest in generation 2: 67.54\n",
      "\n",
      "\n",
      "[9] 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.3388663530349731 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 179.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 55.26\n",
      "Fitness calculated: 55.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.110943078994751 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 175.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 54.06\n",
      "Fitness calculated: 54.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.504896640777588 batch_id=781: 100%|██████████| 782/782 [00:04<00:00, 166.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 59.83\n",
      "Fitness calculated: 59.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.5113803148269653 batch_id=781: 100%|██████████| 782/782 [00:06<00:00, 128.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 44.15\n",
      "Fitness calculated: 44.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.994160532951355 batch_id=781: 100%|██████████| 782/782 [00:06<00:00, 118.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 58.76\n",
      "Fitness calculated: 58.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.1592495441436768 batch_id=781: 100%|██████████| 782/782 [00:07<00:00, 99.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 45.21\n",
      "Fitness calculated: 45.21\n",
      "\n",
      "\n",
      "\n",
      "Fittest in generation 3: 67.54\n",
      "\n",
      "\n",
      "[5] 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=0.6031832695007324 batch_id=781: 100%|██████████| 782/782 [00:09<00:00, 82.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 58.25\n",
      "Fitness calculated: 58.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.1416858434677124 batch_id=781: 100%|██████████| 782/782 [00:08<00:00, 94.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.66\n",
      "Fitness calculated: 51.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.0582005977630615 batch_id=781: 100%|██████████| 782/782 [00:09<00:00, 84.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 59.33\n",
      "Fitness calculated: 59.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.1931568384170532 batch_id=781: 100%|██████████| 782/782 [00:07<00:00, 98.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 47.11\n",
      "Fitness calculated: 47.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1.1243836879730225 batch_id=781: 100%|██████████| 782/782 [00:07<00:00, 101.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 56.82\n",
      "Fitness calculated: 56.82\n",
      "\n",
      "\n",
      "\n",
      "Fittest in generation 4: 67.54\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_generations = 5\n",
    "\n",
    "for g in range(num_generations):\n",
    "    generation.generate()\n",
    "    print(f\"Fittest in generation {g}: {generation.find_fittest().fitness}\\n\\n\")\n",
    "\n",
    "generation.find_fittest().fitness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
