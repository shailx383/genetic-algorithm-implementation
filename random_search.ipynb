{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f191077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import time\n",
    "# from generation import Generation\n",
    "SEARCH_SPACE = {\n",
    "    'k_size_a': [1, 3, 5],\n",
    "    'k_size_b': [1, 3, 5],\n",
    "    'k_size_c': [1, 3, 5],\n",
    "    'k_size_d': [1, 3, 5],\n",
    "    'out_channels_a': [8, 16, 32, 64],\n",
    "    'out_channels_b': [8, 16, 32, 64],\n",
    "    'out_channels_c': [8, 16, 32, 64],\n",
    "    'out_channels_d': [8, 16, 32, 64],\n",
    "    'include_pool_a': [True, False],\n",
    "    'include_pool_b': [True, False],\n",
    "    'include_pool_c': [True, False],\n",
    "    'include_pool_d': [True, False],\n",
    "    'pool_type_a': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_b': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_c': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_d': ['max_pooling','avg_pooling'],\n",
    "    'activation_type_a': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_b': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_c': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_d': ['relu', 'tanh', 'elu', 'selu'], \n",
    "    'include_b': [True, False],\n",
    "    'include_c': [True, False],\n",
    "    'include_d': [True, False],\n",
    "    'include_BN_a': [True, False],\n",
    "    'include_BN_b': [True, False],\n",
    "    'include_BN_c': [True, False],\n",
    "    'include_BN_d': [True, False],\n",
    "    'skip_connection': [False],\n",
    "}\n",
    "FIT_SURVIVAL_RATE = 0.5\n",
    "UNFIT_SURVIVAL_RATE = 0.2\n",
    "MUTATION_RATE = 0.1\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "kwargs = {'batch_size': 64, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(trainset, **kwargs)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(testset, **kwargs)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    " \n",
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, chromosome):\n",
    "        super().__init__()\n",
    "        self.block = chromosome.model\n",
    "        if chromosome.phase == 0:\n",
    "            in_channels = 3\n",
    "            if(chromosome.genes['include_d']):\n",
    "                out_channels = chromosome.genes['out_channels_d']\n",
    "            elif(chromosome.genes['include_c']):\n",
    "                out_channels = chromosome.genes['out_channels_c']\n",
    "            elif(chromosome.genes['include_b']):\n",
    "                out_channels = chromosome.genes['out_channels_b']\n",
    "            else:\n",
    "                out_channels = chromosome.genes['out_channels_a']\n",
    "        else:\n",
    "            if(chromosome.prev_best.genes['include_b']):\n",
    "                in_channels = chromosome.prev_best.genes['out_channels_b']\n",
    "            else:\n",
    "                in_channels = chromosome.prev_best.genes['out_channels_a']\n",
    "            if(chromosome.genes['include_b']):\n",
    "                out_channels = chromosome.genes['out_channels_b']\n",
    "            else:\n",
    "                out_channels = chromosome.genes['out_channels_a']\n",
    "        # self.skip = nn.Conv2d(in_channels, out_channels, 1)\n",
    " \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(out_channels*chromosome.out_dimensions**2,10)\n",
    " \n",
    "    def forward(self, x, chromosome):\n",
    "        # if chromosome.genes['skip_connection']:\n",
    "        #     y = x\n",
    "        #     if chromosome.phase != 0:\n",
    "        #         y = chromosome.prev_best.model(x)\n",
    "        #     y = self.skip(y)\n",
    "        x=self.block(x)\n",
    "        # if chromosome.genes['skip_connection']:\n",
    "        #     x = x + y\n",
    "        x = self.fc(self.flatten(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    " \n",
    " \n",
    "class Chromosome:\n",
    "    def __init__(self,phase:int,prev_best,genes:dict,train_loader,test_loader):\n",
    "        self.phase = phase\n",
    "        self.prev_best = prev_best\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.genes = genes\n",
    "        self.out_dimensions = prev_best.out_dimensions if phase!=0 else 32\n",
    "        self.fitness = -1 \n",
    "        self.model:nn.Module = self.build_model()\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        if self.fitness==-1:\n",
    "            self.fitness = self.fitness_function(train_loader,test_loader)\n",
    " \n",
    "    def build_model(self)->nn.Module:\n",
    "        if(self.prev_best!=None):\n",
    "            prev_best_model:nn.Module = self.prev_best.model\n",
    "        new_model_modules = []\n",
    "        padding_size = 0\n",
    "        if(self.genes['skip_connection']):\n",
    "            padding_size = 16 if self.phase==0 else self.prev_best.out_dimensions//2\n",
    "        if(self.out_dimensions<self.genes['k_size_a']):\n",
    "            self.fitness = 0\n",
    "            return nn.Sequential()\n",
    "        \n",
    "        if(self.phase!=0):\n",
    "            # layer_a = nn.Conv2d(self.prev_best.genes['out_channels_b'] if self.prev_best.genes['include_b'] else self.prev_best.genes['out_channels_a'],self.genes['out_channels_a'],self.genes['k_size_a'],padding = self.genes['k_size_a']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_a = nn.Conv2d(self.prev_best.genes['out_channels_b'] if self.prev_best.genes['include_b'] else self.prev_best.genes['out_channels_a'],self.genes['out_channels_a'],self.genes['k_size_a'],padding = 'same')\n",
    "        else:\n",
    "            # layer_a = nn.Conv2d(3,self.genes['out_channels_a'],self.genes['k_size_a'],padding = self.genes['k_size_a']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_a = nn.Conv2d(3,self.genes['out_channels_a'],self.genes['k_size_a'],padding = 'same')\n",
    "        # self.out_dimensions = (self.out_dimensions-self.genes['k_size_a']+1)\n",
    "        new_model_modules.append(layer_a)\n",
    "        if(self.genes['activation_type_a']=='relu'):\n",
    "            new_model_modules.append(nn.ReLU())\n",
    "        elif(self.genes['activation_type_a']=='elu'):\n",
    "            new_model_modules.append(nn.ELU())\n",
    "        elif(self.genes['activation_type_a']=='selu'):\n",
    "            new_model_modules.append(nn.SELU())\n",
    "        else:\n",
    "            new_model_modules.append(nn.Tanh())\n",
    "        if(self.genes['include_pool_a'] and not self.genes['skip_connection']):\n",
    "            if(self.out_dimensions<2):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            if(self.genes['pool_type_a']=='max_pooling'):\n",
    "                new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                self.out_dimensions = self.out_dimensions//2\n",
    "            elif(self.genes['pool_type_a']=='avg_pooling'):\n",
    "                new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                self.out_dimensions = self.out_dimensions//2\n",
    "            else:\n",
    "                raise Exception('Invalid pool type (a layer)')\n",
    "        \n",
    "        if(self.genes['include_BN_a']):\n",
    "            new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_a']))\n",
    "        \n",
    "        if(self.genes['include_b']):\n",
    "            if(self.out_dimensions<self.genes['k_size_b']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_b)\n",
    "            if(self.genes['activation_type_b']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_b']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_b']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_b'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_b']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_b']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (b layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_b']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_b']))\n",
    "                \n",
    "        if(self.genes['include_c']):\n",
    "            if(self.out_dimensions<self.genes['k_size_c']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_c = nn.Conv2d(self.genes['out_channels_b'],self.genes['out_channels_c'],self.genes['k_size_c'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_c)\n",
    "            if(self.genes['activation_type_c']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_c']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_c']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_c'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_c']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_c']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (c layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_c']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_c']))\n",
    "        \n",
    "        if(self.genes['include_d']):\n",
    "            if(self.out_dimensions<self.genes['k_size_d']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_d = nn.Conv2d(self.genes['out_channels_c'],self.genes['out_channels_d'],self.genes['k_size_d'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_d)\n",
    "            if(self.genes['activation_type_d']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_d']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_d']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_d'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_d']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_d']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (d layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_d']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_d']))\n",
    "        if(self.phase!=0):\n",
    "            new_model = nn.Sequential(prev_best_model,*new_model_modules)\n",
    "        else:\n",
    "            new_model = nn.Sequential(*new_model_modules)\n",
    "        if(self.genes['skip_connection']):\n",
    "            self.out_dimensions = 32 if self.phase==0 else self.prev_best.out_dimensions\n",
    "        # print(new_model)\n",
    "        return new_model            \n",
    " \n",
    "    def fitness_function(self,train_loader,test_loader)->float:\n",
    "        \n",
    "        new_model = FinalModel(self)\n",
    "        #Training loop\n",
    "        optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n",
    "        criterion = F.nll_loss\n",
    "        new_model.to(self.device)\n",
    "        epoch = 1\n",
    "        t_end = time.time()+60*6\n",
    "        while(time.time()<t_end):\n",
    "            pbar = tqdm(train_loader)\n",
    "            new_model.train()\n",
    "            for batch_idx, (data, target) in enumerate(pbar):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = new_model(x = data, chromosome = self)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_description(desc= f'epoch {epoch} loss={loss.item()} batch_id={batch_idx}')\n",
    "            epoch += 1\n",
    "            # Training accuracy\n",
    "            '''\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            new_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in train_loader:\n",
    "                    images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = new_model(images,self)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\"Training accuracy: {}\".format(100 * correct / total))\n",
    "            '''\n",
    "            #Testing loop\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            new_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in test_loader:\n",
    "                    images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = new_model(images,self)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\"Validation accuracy: {}\".format(100 * correct / total))\n",
    "        print(f\"Fitness calculated: {100 * correct / total}\")\n",
    "        return 100 * correct / total\n",
    " \n",
    "    def crossover(self, chromosome):\n",
    "        genes1 = self.genes\n",
    "        genes2 = chromosome.genes\n",
    "        keys = genes1.keys()\n",
    "        new_genes = {}\n",
    "        for key in keys:\n",
    "            new_genes[key] = random.choice([genes1[key], genes2[key]])\n",
    "        new_chromosome = Chromosome(self.phase, self.prev_best, new_genes, self.train_loader, self.test_loader)\n",
    "        return new_chromosome \n",
    "    \n",
    "    def mutation(self):\n",
    "        mutated_gene = random.choice(list(self.genes.keys()))\n",
    "        possible_values = [value for value in SEARCH_SPACE[mutated_gene]]\n",
    "        possible_values.remove(self.genes[mutated_gene])\n",
    "        new_gene_value = random.choice(possible_values)\n",
    "        new_genes = self.genes.copy()\n",
    "        new_genes[mutated_gene] = new_gene_value\n",
    "        new_chromosome = Chromosome(self.phase, self.prev_best, new_genes, self.train_loader, self.test_loader)\n",
    "        return new_chromosome\n",
    "class Generation():\n",
    "    def __init__(self,\n",
    "                 fit_survival_rate: float,\n",
    "                 unfit_survival_rate: float,\n",
    "                 mutation_rate: float,\n",
    "                 pop_size: int,\n",
    "                 phase: int,\n",
    "                 search_space: dict,\n",
    "                 prev_best: Chromosome,\n",
    "                 train_loader,\n",
    "                 test_loader):\n",
    "        self.fit_survival_rate = fit_survival_rate\n",
    "        self.unfit_survival_rate = unfit_survival_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.pop_size = pop_size\n",
    "        self.phase = phase\n",
    "        self.pop = []\n",
    " \n",
    "        for i in range(pop_size):\n",
    "            self.pop.append(Chromosome(phase=phase,\n",
    "                                       prev_best=prev_best,\n",
    "                                       genes=self.make_gene(search_space),\n",
    "                                       train_loader = train_loader,\n",
    "                                       test_loader = test_loader))\n",
    " \n",
    "    def make_gene(self, search_space: dict):\n",
    "        gene = {}\n",
    "        keys = search_space.keys()\n",
    "        for key in keys:\n",
    "            gene[key] = random.choice(search_space[key])\n",
    "        num_layers = random.randrange(1,4)\n",
    "        if num_layers == 4:\n",
    "            gene['include_a'] = True\n",
    "            gene['include_b'] = True\n",
    "            gene['include_c'] = True\n",
    "            gene['include_d'] = True\n",
    "        elif num_layers == 3:\n",
    "            gene['include_a'] = True\n",
    "            gene['include_b'] = True\n",
    "            gene['include_c'] = True\n",
    "            gene['include_d'] = False\n",
    "        elif num_layers == 2:\n",
    "            gene['include_a'] = True\n",
    "            gene['include_b'] = True\n",
    "            gene['include_c'] = False\n",
    "            gene['include_d'] = False\n",
    "        else:\n",
    "            gene['include_a'] = True\n",
    "            gene['include_b'] = False\n",
    "            gene['include_c'] = False\n",
    "            gene['include_d'] = False\n",
    "        return gene\n",
    " \n",
    "    def sort_pop(self):\n",
    "        sorted_pop = sorted(self.pop,\n",
    "                            key=lambda x: x.fitness,\n",
    "                            reverse=True)\n",
    "        self.pop = sorted_pop\n",
    " \n",
    "    def generate(self):\n",
    "        # print(\"start gen\")\n",
    "        self.sort_pop()\n",
    "        # print(f\"{[i.fitness for i in self.pop]}\")\n",
    "        num_fit_selected = int(self.fit_survival_rate * self.pop_size)\n",
    "        num_unfit_selected = int(self.unfit_survival_rate * self.pop_size)\n",
    "        num_mutate = int(self.mutation_rate * self.pop_size)\n",
    " \n",
    "        new_pop = []\n",
    " \n",
    "        for i in range(num_fit_selected):\n",
    "            if(self.pop[i].fitness!=0):\n",
    "                new_pop.append(self.pop[i])\n",
    " \n",
    "        # print('ok')\n",
    " \n",
    " \n",
    "        for i in range(num_unfit_selected):\n",
    "            # print(i)\n",
    "            if(self.pop[self.pop_size-i-1].fitness!=0):\n",
    "                new_pop.append(self.pop[self.pop_size - i - 1])\n",
    " \n",
    "        if (num_mutate > len(new_pop)):\n",
    "            indices_to_mutate = random.sample(\n",
    "                range(0, len(new_pop)), len(new_pop))\n",
    "        else:\n",
    "            indices_to_mutate = random.sample(\n",
    "                range(0, len(new_pop)), num_mutate)\n",
    "        \n",
    "        for i in indices_to_mutate:\n",
    "            if(new_pop[i].fitness!=0):\n",
    "                new_pop[i] = new_pop[i].mutation()\n",
    " \n",
    "        # print(\"Mutuation done.\", [i.fitness for i in new_pop])\n",
    " \n",
    "        parents_list = []\n",
    "        for i in range(self.pop_size - len(new_pop)):\n",
    "            parents = random.sample(range(0, len(new_pop)), 2)\n",
    "            parents_list.append(tuple(parents))\n",
    " \n",
    "        for p1, p2 in parents_list:\n",
    "            if(new_pop[p1].fitness!=0 and new_pop[p2].fitness!=0):\n",
    "                new_pop.append(new_pop[p1].crossover(new_pop[p2]))\n",
    " \n",
    "        self.pop = new_pop\n",
    "        self.pop_size = len(new_pop)\n",
    "        self.sort_pop()\n",
    "        # print(self.pop_size)\n",
    "        print(\"\\n\\n\")\n",
    "        # print(f\"{[i.fitness for i in self.pop]}\")\n",
    " \n",
    "    def find_fittest(self):\n",
    "        self.sort_pop()\n",
    "        return self.pop[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss=0.9666299819946289 batch_id=781: 100%|██████████| 782/782 [00:13<00:00, 56.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 53.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss=1.0185686349868774 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 57.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss=0.9460699558258057 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss=1.034732699394226 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 71.75it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss=0.6332079172134399 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss=0.7472772598266602 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss=0.7945320010185242 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 60.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss=0.6687350869178772 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss=0.9428060054779053 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 loss=0.6042052507400513 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 59.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11 loss=1.5255604982376099 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 64.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12 loss=0.45645710825920105 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13 loss=0.9106433391571045 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14 loss=0.6525105237960815 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.16it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15 loss=0.8650661706924438 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.62it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 61.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16 loss=1.0522900819778442 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 75.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17 loss=1.0732554197311401 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.73it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18 loss=1.7294162511825562 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.94it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 62.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19 loss=0.8960246443748474 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 71.75it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 61.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20 loss=0.8666014671325684 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.01it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21 loss=1.1558893918991089 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.10it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.96\n",
      "Fitness calculated: 63.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss=1.4014966487884521 batch_id=781: 100%|██████████| 782/782 [00:11<00:00, 68.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 46.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss=1.848279356956482 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss=1.0371209383010864 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss=1.516814947128296 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss=1.3892488479614258 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss=1.3192046880722046 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss=1.2206000089645386 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss=1.3848097324371338 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss=1.4361791610717773 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 loss=1.7358946800231934 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 52.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11 loss=1.2997450828552246 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 71.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 52.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12 loss=1.2499113082885742 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13 loss=1.6346641778945923 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 75.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14 loss=1.7489197254180908 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 74.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15 loss=1.465394139289856 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 75.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16 loss=1.2285466194152832 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 75.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17 loss=1.2145520448684692 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 71.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18 loss=0.9633356332778931 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19 loss=1.1852748394012451 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20 loss=1.2485235929489136 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21 loss=1.0679396390914917 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.66\n",
      "Fitness calculated: 51.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss=1.477873682975769 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 47.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss=1.5387226343154907 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 71.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss=1.3820648193359375 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 73.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss=1.262813687324524 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.80it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss=1.0968469381332397 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 71.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss=1.595245599746704 batch_id=781: 100%|██████████| 782/782 [00:10<00:00, 72.11it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Personal\\GitHub\\genetic-algorithm-implementation\\random_search.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m num_individuals \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m generation \u001b[39m=\u001b[39m Generation(fit_survival_rate \u001b[39m=\u001b[39;49m FIT_SURVIVAL_RATE,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                         unfit_survival_rate \u001b[39m=\u001b[39;49m UNFIT_SURVIVAL_RATE,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                         mutation_rate \u001b[39m=\u001b[39;49m MUTATION_RATE,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                         pop_size \u001b[39m=\u001b[39;49m num_individuals,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                         phase \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                         search_space \u001b[39m=\u001b[39;49m SEARCH_SPACE,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         prev_best \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         train_loader \u001b[39m=\u001b[39;49m train_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                         test_loader \u001b[39m=\u001b[39;49m test_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m generation\u001b[39m.\u001b[39msort_pop()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest Fitnes: \u001b[39m\u001b[39m{\u001b[39;00mgeneration\u001b[39m.\u001b[39mfind_fittest()\u001b[39m.\u001b[39mfitness\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\Personal\\GitHub\\genetic-algorithm-implementation\\random_search.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=350'>351</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpop \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=352'>353</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(pop_size):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=353'>354</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpop\u001b[39m.\u001b[39mappend(Chromosome(phase\u001b[39m=\u001b[39;49mphase,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=354'>355</a>\u001b[0m                                prev_best\u001b[39m=\u001b[39;49mprev_best,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=355'>356</a>\u001b[0m                                genes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_gene(search_space),\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=356'>357</a>\u001b[0m                                train_loader \u001b[39m=\u001b[39;49m train_loader,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=357'>358</a>\u001b[0m                                test_loader \u001b[39m=\u001b[39;49m test_loader))\n",
      "\u001b[1;32md:\\Personal\\GitHub\\genetic-algorithm-implementation\\random_search.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_loader \u001b[39m=\u001b[39m test_loader\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness\u001b[39m==\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_function(train_loader,test_loader)\n",
      "\u001b[1;32md:\\Personal\\GitHub\\genetic-algorithm-implementation\\random_search.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=275'>276</a>\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(train_loader)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=276'>277</a>\u001b[0m new_model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=277'>278</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=278'>279</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), target\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Personal/GitHub/genetic-algorithm-implementation/random_search.ipynb#W1sZmlsZQ%3D%3D?line=279'>280</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     95\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\maitr\\miniconda3\\envs\\dl_project\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_individuals = 10\n",
    "generation = Generation(fit_survival_rate = FIT_SURVIVAL_RATE,\n",
    "                        unfit_survival_rate = UNFIT_SURVIVAL_RATE,\n",
    "                        mutation_rate = MUTATION_RATE,\n",
    "                        pop_size = num_individuals,\n",
    "                        phase = 0,\n",
    "                        search_space = SEARCH_SPACE,\n",
    "                        prev_best = None,\n",
    "                        train_loader = train_loader,\n",
    "                        test_loader = test_loader)\n",
    "generation.sort_pop()\n",
    "print(f\"Best Fitnes: {generation.find_fittest().fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
