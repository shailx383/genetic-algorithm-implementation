{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIT_SURVIVAL_RATE = 0.5\n",
    "UNFIT_SURVIVAL_RATE = 0.2\n",
    "MUTATION_RATE = 0.1\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "kwargs = {'batch_size': 64, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(trainset, **kwargs)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(testset, **kwargs)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "SEARCH_SPACE = {\n",
    "    'k_size_a': [1, 3, 5],\n",
    "    'k_size_b': [1, 3, 5],\n",
    "    'out_channels_a': [8, 16, 32, 64],\n",
    "    'out_channels_b': [8, 16, 32, 64],\n",
    "    'include_pool_a': [True, False],\n",
    "    'include_pool_b': [True, False],\n",
    "    'pool_type_a': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_b': ['max_pooling','avg_pooling'],\n",
    "    'activation_type_a': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_b': ['relu', 'tanh', 'elu', 'selu'], \n",
    "    'include_b': [True, False],\n",
    "    'include_BN_a': [True, False],\n",
    "    'include_BN_b': [True, False],\n",
    "    'skip_connection': [True, False],\n",
    "}\n",
    "\n",
    "INIT_SEARCH_SPACE = {\n",
    "    'k_size_a': [1, 3, 5],\n",
    "    'k_size_b': [1, 3, 5],\n",
    "    'out_channels_a': [8, 16, 32, 64],\n",
    "    'out_channels_b': [8, 16, 32, 64],\n",
    "    'include_pool_a': [True, False],\n",
    "    'include_pool_b': [True, False],\n",
    "    'pool_type_a': ['max_pooling','avg_pooling'],\n",
    "    'pool_type_b': ['max_pooling','avg_pooling'],\n",
    "    'activation_type_a': ['relu', 'tanh', 'elu', 'selu'],\n",
    "    'activation_type_b': ['relu', 'tanh', 'elu', 'selu'], \n",
    "    'include_b': [False],\n",
    "    'include_BN_a': [True, False],\n",
    "    'include_BN_b': [True, False],\n",
    "    'skip_connection': [True, False],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, chromosome):\n",
    "        super().__init__()\n",
    "        self.block = chromosome.model\n",
    "        if chromosome.phase == 0:\n",
    "            in_channels = 3\n",
    "            out_channels = chromosome.genes['out_channels_b']\n",
    "        else:\n",
    "            if(chromosome.prev_best.genes['include_b']):\n",
    "                in_channels = chromosome.prev_best.genes['out_channels_b']\n",
    "            else:\n",
    "                in_channels = chromosome.prev_best.genes['out_channels_a']\n",
    "            if(chromosome.genes['include_b']):\n",
    "                out_channels = chromosome.genes['out_channels_b']\n",
    "            else:\n",
    "                out_channels = chromosome.genes['out_channels_a']\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, 1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(out_channels*chromosome.out_dimensions**2,10)\n",
    "\n",
    "    def forward(self, x, chromosome):\n",
    "        if chromosome.genes['skip_connection']:\n",
    "            y = x\n",
    "            if chromosome.phase != 0:\n",
    "                y = chromosome.prev_best.model(x)\n",
    "            y = self.skip(y)\n",
    "        x=self.block(x)\n",
    "        if chromosome.genes['skip_connection']:\n",
    "            x = x + y\n",
    "        x = self.fc(self.flatten(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    def __init__(self,phase:int,prev_best,genes:dict,train_loader,test_loader):\n",
    "        self.phase = phase\n",
    "        self.prev_best = prev_best\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.genes = genes\n",
    "        self.out_dimensions = prev_best.out_dimensions if phase!=0 else 32\n",
    "        self.fitness = -1 \n",
    "        self.model:nn.Module = self.build_model()\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        if self.fitness==-1:\n",
    "            self.fitness = self.fitness_function(train_loader,test_loader)\n",
    "\n",
    "    def build_model(self)->nn.Module:\n",
    "        if(self.prev_best!=None):\n",
    "            prev_best_model:nn.Module = self.prev_best.model\n",
    "        new_model_modules = []\n",
    "        padding_size = 0\n",
    "        if(self.genes['skip_connection']):\n",
    "            padding_size = 16 if self.phase==0 else self.prev_best.out_dimensions//2\n",
    "        if(self.out_dimensions<self.genes['k_size_a']):\n",
    "            self.fitness = 0\n",
    "            return nn.Sequential()\n",
    "        \n",
    "        if(self.phase!=0):\n",
    "            # layer_a = nn.Conv2d(self.prev_best.genes['out_channels_b'] if self.prev_best.genes['include_b'] else self.prev_best.genes['out_channels_a'],self.genes['out_channels_a'],self.genes['k_size_a'],padding = self.genes['k_size_a']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_a = nn.Conv2d(self.prev_best.genes['out_channels_b'] if self.prev_best.genes['include_b'] else self.prev_best.genes['out_channels_a'],self.genes['out_channels_a'],self.genes['k_size_a'],padding = 'same')\n",
    "        else:\n",
    "            # layer_a = nn.Conv2d(3,self.genes['out_channels_a'],self.genes['k_size_a'],padding = self.genes['k_size_a']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_a = nn.Conv2d(3,self.genes['out_channels_a'],self.genes['k_size_a'],padding = 'same')\n",
    "        # self.out_dimensions = (self.out_dimensions-self.genes['k_size_a']+1)\n",
    "        new_model_modules.append(layer_a)\n",
    "        if(self.genes['activation_type_a']=='relu'):\n",
    "            new_model_modules.append(nn.ReLU())\n",
    "        elif(self.genes['activation_type_a']=='elu'):\n",
    "            new_model_modules.append(nn.ELU())\n",
    "        elif(self.genes['activation_type_a']=='selu'):\n",
    "            new_model_modules.append(nn.SELU())\n",
    "        else:\n",
    "            new_model_modules.append(nn.Tanh())\n",
    "        if(self.genes['include_pool_a'] and not self.genes['skip_connection']):\n",
    "            if(self.out_dimensions<2):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            if(self.genes['pool_type_a']=='max_pooling'):\n",
    "                new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                self.out_dimensions = self.out_dimensions//2\n",
    "            elif(self.genes['pool_type_a']=='avg_pooling'):\n",
    "                new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                self.out_dimensions = self.out_dimensions//2\n",
    "            else:\n",
    "                raise Exception('Invalid pool type (a layer)')\n",
    "        \n",
    "        if(self.genes['include_BN_a']):\n",
    "            new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_a']))\n",
    "        \n",
    "        if(self.genes['include_b'] or self.phase==0):\n",
    "            if(self.out_dimensions<self.genes['k_size_b']):\n",
    "                self.fitness = 0\n",
    "                return nn.Sequential()\n",
    "            # layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = self.genes['k_size_b']//2 if self.genes['skip_connection'] else 0)\n",
    "            layer_b = nn.Conv2d(self.genes['out_channels_a'],self.genes['out_channels_b'],self.genes['k_size_b'],padding = 'same')\n",
    "            # self.out_dimensions = (self.out_dimensions-self.genes['k_size_b']+1)\n",
    "            new_model_modules.append(layer_b)\n",
    "            if(self.genes['activation_type_b']=='relu'):\n",
    "                new_model_modules.append(nn.ReLU())\n",
    "            elif(self.genes['activation_type_b']=='elu'):\n",
    "                new_model_modules.append(nn.ELU())\n",
    "            elif(self.genes['activation_type_b']=='selu'):\n",
    "                new_model_modules.append(nn.SELU())\n",
    "            else:\n",
    "                new_model_modules.append(nn.Tanh())\n",
    "            \n",
    "            if(self.genes['include_pool_b'] and not self.genes['skip_connection']):\n",
    "                if(self.out_dimensions<2):\n",
    "                    self.fitness = 0\n",
    "                    return nn.Sequential()\n",
    "                if(self.genes['pool_type_b']=='max_pooling'):\n",
    "                    new_model_modules.append(nn.MaxPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.MaxPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                elif(self.genes['pool_type_b']=='avg_pooling'):\n",
    "                    new_model_modules.append(nn.AvgPool2d(2,2,padding = padding_size))\n",
    "                    # new_model_modules.append(nn.AvgPool2d(2,2,padding = 'same'))\n",
    "                    self.out_dimensions = self.out_dimensions//2\n",
    "                else:\n",
    "                    raise Exception('Invalid pool type (b layer)')\n",
    "                \n",
    "            if(self.genes['include_BN_b']):\n",
    "                new_model_modules.append(nn.BatchNorm2d(self.genes['out_channels_b']))\n",
    "        if(self.phase!=0):\n",
    "            new_model = nn.Sequential(prev_best_model,*new_model_modules)\n",
    "        else:\n",
    "            new_model = nn.Sequential(*new_model_modules)\n",
    "        if(self.genes['skip_connection']):\n",
    "            self.out_dimensions = 32 if self.phase==0 else self.prev_best.out_dimensions\n",
    "        # print(new_model)\n",
    "        return new_model            \n",
    "\n",
    "    def fitness_function(self,train_loader,test_loader)->float:\n",
    "        \n",
    "        new_model = FinalModel(self)\n",
    "        #Training loop\n",
    "        optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n",
    "        criterion = F.nll_loss\n",
    "        new_model.to(self.device)\n",
    "        num_epochs = 5\n",
    "        for epoch in range(num_epochs):\n",
    "            pbar = tqdm(train_loader)\n",
    "            new_model.train()\n",
    "            for batch_idx, (data, target) in enumerate(pbar):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = new_model(x = data, chromosome = self)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_description(desc= f'epoch {epoch} loss={loss.item()} batch_id={batch_idx}')\n",
    "            # Training accuracy\n",
    "            '''\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            new_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in train_loader:\n",
    "                    images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = new_model(images,self)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\"Training accuracy: {}\".format(100 * correct / total))\n",
    "            '''\n",
    "            #Testing loop\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            new_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in test_loader:\n",
    "                    images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = new_model(images,self)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\"Validation accuracy: {}\".format(100 * correct / total))\n",
    "        print(f\"Fitness calculated: {100 * correct / total}\")\n",
    "        return 100 * correct / total\n",
    "\n",
    "    def crossover(self, chromosome):\n",
    "        genes1 = self.genes\n",
    "        genes2 = chromosome.genes\n",
    "        keys = genes1.keys()\n",
    "        new_genes = {}\n",
    "        for key in keys:\n",
    "            new_genes[key] = random.choice([genes1[key], genes2[key]])\n",
    "        new_chromosome = Chromosome(self.phase, self.prev_best, new_genes, self.train_loader, self.test_loader)\n",
    "        return new_chromosome \n",
    "    \n",
    "    def mutation(self):\n",
    "        mutated_gene = random.choice(list(self.genes.keys()))\n",
    "        possible_values = [value for value in SEARCH_SPACE[mutated_gene]]\n",
    "        possible_values.remove(self.genes[mutated_gene])\n",
    "        new_gene_value = random.choice(possible_values)\n",
    "        new_genes = self.genes.copy()\n",
    "        new_genes[mutated_gene] = new_gene_value\n",
    "        new_chromosome = Chromosome(self.phase, self.prev_best, new_genes, self.train_loader, self.test_loader)\n",
    "        return new_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generation():\n",
    "    def __init__(self,\n",
    "                 fit_survival_rate: float,\n",
    "                 unfit_survival_rate: float,\n",
    "                 mutation_rate: float,\n",
    "                 pop_size: int,\n",
    "                 phase: int,\n",
    "                 search_space: dict,\n",
    "                 prev_best: Chromosome,\n",
    "                 train_loader,\n",
    "                 test_loader):\n",
    "        self.fit_survival_rate = fit_survival_rate\n",
    "        self.unfit_survival_rate = unfit_survival_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.pop_size = pop_size\n",
    "        self.phase = phase\n",
    "        self.pop = []\n",
    "\n",
    "        for i in range(pop_size):\n",
    "            self.pop.append(Chromosome(phase=phase,\n",
    "                                       prev_best=prev_best,\n",
    "                                       genes=self.make_gene(search_space),\n",
    "                                       train_loader = train_loader,\n",
    "                                       test_loader = test_loader))\n",
    "\n",
    "    def make_gene(self, search_space: dict):\n",
    "        gene = {}\n",
    "        keys = search_space.keys()\n",
    "        for key in keys:\n",
    "            gene[key] = random.choice(search_space[key])\n",
    "        if self.phase == 0:\n",
    "            gene['include_b'] = True\n",
    "        return gene\n",
    "\n",
    "    def sort_pop(self):\n",
    "        sorted_pop = sorted(self.pop,\n",
    "                            key=lambda x: x.fitness,\n",
    "                            reverse=True)\n",
    "        self.pop = sorted_pop\n",
    "\n",
    "    def generate(self):\n",
    "        # print(\"start gen\")\n",
    "        self.sort_pop()\n",
    "        # print(f\"{[i.fitness for i in self.pop]}\")\n",
    "        num_fit_selected = int(self.fit_survival_rate * self.pop_size)\n",
    "        num_unfit_selected = int(self.unfit_survival_rate * self.pop_size)\n",
    "        num_mutate = int(self.mutation_rate * self.pop_size)\n",
    "\n",
    "        new_pop = []\n",
    "\n",
    "        for i in range(num_fit_selected):\n",
    "            if(self.pop[i].fitness!=0):\n",
    "                new_pop.append(self.pop[i])\n",
    "\n",
    "        # print('ok')\n",
    "\n",
    "\n",
    "        for i in range(num_unfit_selected):\n",
    "            # print(i)\n",
    "            if(self.pop[self.pop_size-i-1].fitness!=0):\n",
    "                new_pop.append(self.pop[self.pop_size - i - 1])\n",
    "\n",
    "        if (num_mutate > len(new_pop)):\n",
    "            indices_to_mutate = random.sample(\n",
    "                range(0, len(new_pop)), len(new_pop))\n",
    "        else:\n",
    "            indices_to_mutate = random.sample(\n",
    "                range(0, len(new_pop)), num_mutate)\n",
    "        \n",
    "        for i in indices_to_mutate:\n",
    "            if(new_pop[i].fitness!=0):\n",
    "                new_pop[i] = new_pop[i].mutation()\n",
    "\n",
    "        # print(\"Mutuation done.\", [i.fitness for i in new_pop])\n",
    "\n",
    "        parents_list = []\n",
    "        for i in range(self.pop_size - len(new_pop)):\n",
    "            parents = random.sample(range(0, len(new_pop)), 2)\n",
    "            parents_list.append(tuple(parents))\n",
    "\n",
    "        for p1, p2 in parents_list:\n",
    "            if(new_pop[p1].fitness!=0 and new_pop[p2].fitness!=0):\n",
    "                new_pop.append(new_pop[p1].crossover(new_pop[p2]))\n",
    "\n",
    "        self.pop = new_pop\n",
    "        self.pop_size = len(new_pop)\n",
    "        self.sort_pop()\n",
    "        # print(self.pop_size)\n",
    "        print(\"\\n\\n\")\n",
    "        # print(f\"{[i.fitness for i in self.pop]}\")\n",
    "\n",
    "    def find_fittest(self):\n",
    "        self.sort_pop()\n",
    "        return self.pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_individuals = 15\n",
    "generation = Generation(fit_survival_rate = FIT_SURVIVAL_RATE,\n",
    "                        unfit_survival_rate = UNFIT_SURVIVAL_RATE,\n",
    "                        mutation_rate = MUTATION_RATE,\n",
    "                        pop_size = num_individuals,\n",
    "                        phase = 0,\n",
    "                        search_space = INIT_SEARCH_SPACE, #to initialize with no b for sure\n",
    "                        prev_best = None,\n",
    "                        train_loader = train_loader,\n",
    "                        test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 15\n",
    "\n",
    "for i in range (rounds):\n",
    "   index1 = random.randrange(0, generation.pop_size)\n",
    "   flag = True\n",
    "   while(flag):\n",
    "     index2 = random.randrange(0, generation.pop_size)\n",
    "     if(index2 > index1):\n",
    "         flag = False\n",
    "    \n",
    "   if(generation.pop[index1].fitness > generation.pop[index2].fitness):\n",
    "       generation.pop.append(generation.pop[index1].mutation())\n",
    "       #Kill the index2\n",
    "       generation.pop.pop(index2)\n",
    "       #Reproduce the first one\n",
    "\n",
    "   else:\n",
    "        generation.pop.append(generation.pop[index2].mutation())\n",
    "        #Kill the index1\n",
    "        generation.pop.pop(index1)\n",
    "        #Reproduce the second one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation.sort_pop()\n",
    "generation.find_fittest.fitness()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
